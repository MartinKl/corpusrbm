{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Notker\n",
    "\n",
    "This project is supposed to clean all layers from disjunct annotations. Good luck üçÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# python std libs\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "# own libs\n",
    "from ddd import ad_api\n",
    "from ddd.ad_api import corpus\n",
    "# 3rd party libs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IGNORE_TIERS = ('edition', 'character', 'page', 'default', 'translation', 'posLemma', 'verse', 'comp', 'chapter', 'line', 'pos', 'inflectionClassLemma', 'rhyme', 'markup', 'inflectionClass', 'inflection')\n",
    "CORPUS_HOME = ad_api.CONFIG[ad_api.NAMES.DATA_HOME]\n",
    "TRAIN_NAMES = [\n",
    "    'DDD-AD-Murbacher_Hymnen',\n",
    "    'DDD-AD-Isidor_Latein',\n",
    "    'DDD-AD-Tatian',\n",
    "    'DDD-AD-Benediktiner_Regel',\n",
    "    'DDD-AD-Kleinere_Althochdeutsche_Denkm√§ler',\n",
    "    'DDD-AD-Kleinere_Alts√§chsische_Denkm√§ler',\n",
    "    'DDD-AD-Otfrid',\n",
    "    'DDD-AD-Genesis',\n",
    "    'DDD-AD-Benediktiner_Regel_Latein',\n",
    "    'DDD-AD-Physiologus',\n",
    "    'DDD-AD-Monsee',\n",
    "    'DDD-AD-Tatian_Latein',\n",
    "    'DDD-AD-Heliand',\n",
    "    'DDD-AD-Murbacher_Hymnen_Latein',\n",
    "    'DDD-AD-Isidor'\n",
    "]\n",
    "NOTKER = [\n",
    "    'DDD-AD-Z-Notker_Boethius-Categoriae',\n",
    "    'DDD-AD-Z-Notker_Boethius-De_Interpretatione'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting /home/klotzmaz/Documents/referenzkorpus_altdeutsch/elan_repo/DDD-AD-Murbacher_Hymnen ...\n",
      "Done with DDD-AD-Murbacher_Hymnen\n",
      "Starting /home/klotzmaz/Documents/referenzkorpus_altdeutsch/elan_repo/DDD-AD-Isidor_Latein ...\n",
      "Done with DDD-AD-Isidor_Latein\n",
      "Starting /home/klotzmaz/Documents/referenzkorpus_altdeutsch/elan_repo/DDD-AD-Tatian ...\n",
      "Done with DDD-AD-Tatian\n",
      "Starting /home/klotzmaz/Documents/referenzkorpus_altdeutsch/elan_repo/DDD-AD-Benediktiner_Regel ...\n",
      "Done with DDD-AD-Benediktiner_Regel\n",
      "Starting /home/klotzmaz/Documents/referenzkorpus_altdeutsch/elan_repo/DDD-AD-Kleinere_Althochdeutsche_Denkm√§ler ...\n",
      "Done with DDD-AD-Kleinere_Althochdeutsche_Denkm√§ler\n",
      "Starting /home/klotzmaz/Documents/referenzkorpus_altdeutsch/elan_repo/DDD-AD-Kleinere_Alts√§chsische_Denkm√§ler ...\n",
      "Done with DDD-AD-Kleinere_Alts√§chsische_Denkm√§ler\n",
      "Starting /home/klotzmaz/Documents/referenzkorpus_altdeutsch/elan_repo/DDD-AD-Otfrid ...\n",
      "Done with DDD-AD-Otfrid\n",
      "Starting /home/klotzmaz/Documents/referenzkorpus_altdeutsch/elan_repo/DDD-AD-Genesis ...\n",
      "Done with DDD-AD-Genesis\n",
      "Starting /home/klotzmaz/Documents/referenzkorpus_altdeutsch/elan_repo/DDD-AD-Benediktiner_Regel_Latein ...\n",
      "Done with DDD-AD-Benediktiner_Regel_Latein\n",
      "Starting /home/klotzmaz/Documents/referenzkorpus_altdeutsch/elan_repo/DDD-AD-Physiologus ...\n",
      "Done with DDD-AD-Physiologus\n",
      "Starting /home/klotzmaz/Documents/referenzkorpus_altdeutsch/elan_repo/DDD-AD-Monsee ...\n",
      "Done with DDD-AD-Monsee\n",
      "Starting /home/klotzmaz/Documents/referenzkorpus_altdeutsch/elan_repo/DDD-AD-Tatian_Latein ...\n",
      "Done with DDD-AD-Tatian_Latein\n",
      "Starting /home/klotzmaz/Documents/referenzkorpus_altdeutsch/elan_repo/DDD-AD-Heliand ...\n",
      "Done with DDD-AD-Heliand\n",
      "Starting /home/klotzmaz/Documents/referenzkorpus_altdeutsch/elan_repo/DDD-AD-Murbacher_Hymnen_Latein ...\n",
      "Done with DDD-AD-Murbacher_Hymnen_Latein\n",
      "Starting /home/klotzmaz/Documents/referenzkorpus_altdeutsch/elan_repo/DDD-AD-Isidor ...\n",
      "Done with DDD-AD-Isidor\n"
     ]
    }
   ],
   "source": [
    "vocabs = {\n",
    "    'text': {},\n",
    "    'lemma': {}\n",
    "}\n",
    "data = {}\n",
    "for cname in TRAIN_NAMES:\n",
    "    cdir = os.path.join(CORPUS_HOME, cname)\n",
    "    print('Starting', cdir, '...')\n",
    "    subcorpus = ad_api.corpus.Corpus.from_directory(cdir, ignore_tiers=IGNORE_TIERS)    \n",
    "    \n",
    "    for doc in subcorpus:\n",
    "        lang = max(doc.languages, key=lambda l: doc.languages[l])\n",
    "        if lang not in data: data[lang] = {'text': [], 'lemma': []}\n",
    "        doc_ix_lists = {\n",
    "            'text': [],\n",
    "            'lemma': []\n",
    "        }\n",
    "        for annotationset in doc:\n",
    "            collected = {}\n",
    "            predecessor = {'text': None, 'lemma': None}            \n",
    "            for anno_key in annotationset:\n",
    "                if anno_key == 'lemma' or anno_key == 'text':\n",
    "                    collected[anno_key] = annotationset[anno_key]                \n",
    "                    if predecessor[anno_key] == collected[anno_key]:\n",
    "                        raise ValueError('Duplicate!')\n",
    "                    elif len(collected) == 2:\n",
    "                        predecessor = collected\n",
    "            for key, anno in collected.items():\n",
    "                if anno.value in vocabs[key]:\n",
    "                    doc_ix_lists[key].append(vocabs[key][anno.value])\n",
    "                else:\n",
    "                    doc_ix_lists[key].append(len(vocabs[key]))\n",
    "                    vocabs[key][anno.value] = len(vocabs[key])\n",
    "            for k, v in doc_ix_lists.items():\n",
    "                data[lang][k].append(v)\n",
    "            \n",
    "    print('Done with', cname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with gmh\n",
      "Done with goh\n",
      "Done with lat\n",
      "Done with ohg\n",
      "Done with osx\n"
     ]
    }
   ],
   "source": [
    "for lang in data:    \n",
    "    for k, l in data[lang].items():\n",
    "        with open('{}_{}.npy'.format(lang, k), 'wb') as f:\n",
    "            np.save(f, np.array(l))\n",
    "    print('Done with', lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('vocabs.pkl', 'wb') as f:\n",
    "    pickle.dump(vocabs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
